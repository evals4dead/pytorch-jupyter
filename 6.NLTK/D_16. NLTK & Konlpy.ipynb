{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK & Konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.raw(\"milton-paradise.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Paradise Lost by John Milton 1667] \n",
      " \n",
      " \n",
      "Book I \n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of that forbidden tree whose mortal taste \n",
      "Brought death into the World, and all our woe, \n",
      "With loss of Eden, till one greater Man \n",
      "Restore us, and regain the blissful seat, \n",
      "Sing, Heavenly Muse, that, on the secret top \n",
      "Of Oreb, or of Sinai, didst inspire \n",
      "That shepherd who first taught the chosen seed \n",
      "In the beginning how the heavens and earth \n",
      "Rose out of Chaos: or, if Sion hill \n",
      "Delight thee mor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paradise lost by john milton 1667] \n",
      " \n",
      " \n",
      "book i \n",
      " \n",
      " \n",
      "of man's first disobedience, and the fruit \n",
      "of that forbidden tree whose mortal taste \n",
      "brought death into the world, and all our woe, \n",
      "with loss of eden, till one greater man \n",
      "restore us, and regain the blissful seat, \n",
      "sing, heavenly muse, that, on the secret top \n",
      "of oreb, or of sinai, didst inspire \n",
      "that shepherd who first taught the chosen seed \n",
      "in the beginning how the heavens and earth \n",
      "rose out of chaos: or, if sion hill \n",
      "delight thee mor\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'paradise', 'lost', 'by', 'john', 'milton', '1667', ']', 'book', 'i', 'of', 'man', \"'s\", 'first', 'disobedience', ',', 'and', 'the', 'fruit', 'of', 'that', 'forbidden', 'tree', 'whose', 'mortal', 'taste', 'brought', 'death', 'into', 'the', 'world', ',', 'and', 'all', 'our', 'woe', ',', 'with', 'loss', 'of', 'eden', ',', 'till', 'one', 'greater', 'man', 'restore', 'us', ',', 'and', 'regain', 'the', 'blissful', 'seat', ',', 'sing', ',', 'heavenly', 'muse', ',', 'that', ',', 'on', 'the', 'secret', 'top', 'of', 'oreb', ',', 'or', 'of', 'sinai', ',', 'didst', 'inspire', 'that', 'shepherd', 'who', 'first', 'taught', 'the', 'chosen', 'seed', 'in', 'the', 'beginning', 'how', 'the', 'heavens', 'and', 'earth', 'rose', 'out', 'of', 'chaos', ':', 'or', ',', 'if', 'sion', 'hill', 'delight', 'thee', 'mor']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(text[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paradise', 'lost', 'by', 'john', 'milton', '1667', 'book', 'i', 'of', 'man', 's', 'first', 'disobedience', 'and', 'the', 'fruit', 'of', 'that', 'forbidden', 'tree', 'whose', 'mortal', 'taste', 'brought', 'death', 'into', 'the', 'world', 'and', 'all', 'our', 'woe', 'with', 'loss', 'of', 'eden', 'till', 'one', 'greater', 'man', 'restore', 'us', 'and', 'regain', 'the', 'blissful', 'seat', 'sing', 'heavenly', 'muse', 'that', 'on', 'the', 'secret', 'top', 'of', 'oreb', 'or', 'of', 'sinai', 'didst', 'inspire', 'that', 'shepherd', 'who', 'first', 'taught', 'the', 'chosen', 'seed', 'in', 'the', 'beginning', 'how', 'the', 'heavens', 'and', 'earth', 'rose', 'out', 'of', 'chaos', 'or', 'if', 'sion', 'hill', 'delight', 'thee', 'mor']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokens = RegexpTokenizer(\"[\\w]+\").tokenize(text[:500])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"it's\", 'into', 'nor', 'just', 'shouldn', 'only', 'aren', 'very', \"couldn't\", 'until', 'above', 'once', 'over', 'who', 'doesn', 'itself', 'an', 'weren', 'haven', 'in', \"you'd\", 'if', \"didn't\", \"she's\", 'no', 'whom', 'myself', 'for', 'why', \"shouldn't\", 'i', 'so', \"you're\", 'herself', 'them', 'any', \"aren't\", 'not', 'yourself', 'then', 'd', 'off', 'o', 'll', 'each', 's', 'its', \"mustn't\", 'will', \"you've\", 'you', 'has', 'her', 'these', 'don', 'before', 'won', 'hasn', 'ours', 'both', \"hadn't\", 'we', 'am', 'between', 'with', 'was', 'where', 'didn', \"you'll\", 'out', \"wouldn't\", 'about', 've', \"wasn't\", 'there', \"won't\", 're', 'a', 'as', 'having', 'own', 'ain', \"doesn't\", 'or', 'this', 'and', 'is', 'during', 'same', 'hers', 'she', 'do', 'wasn', 'his', 'it', 'to', \"weren't\", 'yourselves', 'mustn', 'hadn', 'too', 'shan', 'what', 'at', 'when', 'ourselves', \"hasn't\", 'he', 'doing', 'on', 'are', 'theirs', 'had', 'some', 'than', 'up', 'under', 'other', 'him', 'because', 'me', 'yours', 'himself', 'themselves', 'my', 'which', 'further', 'here', 'were', 'most', 'did', 'how', 'those', 'they', 'being', 'through', 'by', 'below', 'ma', 'be', \"don't\", 'more', 'our', 'mightn', 'the', 'can', 'but', \"shan't\", 'few', \"needn't\", 'couldn', 'from', 'have', 't', 'does', 'down', 'wouldn', \"mightn't\", 'while', 'after', 'that', 'been', \"that'll\", 'again', 'their', 'your', \"should've\", 'now', 'needn', 'of', 'should', 'against', \"haven't\", \"isn't\", 'such', 'y', 'm', 'all', 'isn'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopping = set(stopwords.words('english'))\n",
    "print(stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paradise', 'lost', 'john', 'milton', '1667', 'book', 'man', 'first', 'disobedience', 'fruit', 'forbidden', 'tree', 'whose', 'mortal', 'taste', 'brought', 'death', 'world', 'woe', 'loss', 'eden', 'till', 'one', 'greater', 'man', 'restore', 'us', 'regain', 'blissful', 'seat', 'sing', 'heavenly', 'muse', 'secret', 'top', 'oreb', 'sinai', 'didst', 'inspire', 'shepherd', 'first', 'taught', 'chosen', 'seed', 'beginning', 'heavens', 'earth', 'rose', 'chaos', 'sion', 'hill', 'delight', 'thee', 'mor']\n"
     ]
    }
   ],
   "source": [
    "print([token for token in tokens if not token in stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'the' in stopping, 'paradise' in stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paradis',\n",
       " 'lost',\n",
       " 'by',\n",
       " 'john',\n",
       " 'milton',\n",
       " '1667',\n",
       " 'book',\n",
       " 'i',\n",
       " 'of',\n",
       " 'man',\n",
       " 's',\n",
       " 'first',\n",
       " 'disobedi',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fruit',\n",
       " 'of',\n",
       " 'that',\n",
       " 'forbidden',\n",
       " 'tree',\n",
       " 'whose',\n",
       " 'mortal',\n",
       " 'tast',\n",
       " 'brought',\n",
       " 'death',\n",
       " 'into',\n",
       " 'the',\n",
       " 'world',\n",
       " 'and',\n",
       " 'all',\n",
       " 'our',\n",
       " 'woe',\n",
       " 'with',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'eden',\n",
       " 'till',\n",
       " 'one',\n",
       " 'greater',\n",
       " 'man',\n",
       " 'restor',\n",
       " 'us',\n",
       " 'and',\n",
       " 'regain',\n",
       " 'the',\n",
       " 'bliss',\n",
       " 'seat',\n",
       " 'sing',\n",
       " 'heavenli',\n",
       " 'muse',\n",
       " 'that',\n",
       " 'on',\n",
       " 'the',\n",
       " 'secret',\n",
       " 'top',\n",
       " 'of',\n",
       " 'oreb',\n",
       " 'or',\n",
       " 'of',\n",
       " 'sinai',\n",
       " 'didst',\n",
       " 'inspir',\n",
       " 'that',\n",
       " 'shepherd',\n",
       " 'who',\n",
       " 'first',\n",
       " 'taught',\n",
       " 'the',\n",
       " 'chosen',\n",
       " 'seed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'begin',\n",
       " 'how',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'earth',\n",
       " 'rose',\n",
       " 'out',\n",
       " 'of',\n",
       " 'chao',\n",
       " 'or',\n",
       " 'if',\n",
       " 'sion',\n",
       " 'hill',\n",
       " 'delight',\n",
       " 'thee',\n",
       " 'mor']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "[PorterStemmer().stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paradise', 'NN'), ('lost', 'VBN'), ('by', 'IN'), ('john', 'NN'), ('milton', 'NN'), ('1667', 'CD'), ('book', 'NN'), ('i', 'NN'), ('of', 'IN'), ('man', 'NN'), ('s', 'NN'), ('first', 'JJ'), ('disobedience', 'NN'), ('and', 'CC'), ('the', 'DT'), ('fruit', 'NN'), ('of', 'IN'), ('that', 'DT'), ('forbidden', 'JJ'), ('tree', 'NN'), ('whose', 'WP$'), ('mortal', 'JJ'), ('taste', 'NN'), ('brought', 'VBD'), ('death', 'NN'), ('into', 'IN'), ('the', 'DT'), ('world', 'NN'), ('and', 'CC'), ('all', 'DT'), ('our', 'PRP$'), ('woe', 'NN'), ('with', 'IN'), ('loss', 'NN'), ('of', 'IN'), ('eden', 'JJ'), ('till', 'NN'), ('one', 'CD'), ('greater', 'JJR'), ('man', 'NN'), ('restore', 'VB'), ('us', 'PRP'), ('and', 'CC'), ('regain', 'VB'), ('the', 'DT'), ('blissful', 'JJ'), ('seat', 'NN'), ('sing', 'VBG'), ('heavenly', 'RB'), ('muse', 'VBP'), ('that', 'IN'), ('on', 'IN'), ('the', 'DT'), ('secret', 'JJ'), ('top', 'NN'), ('of', 'IN'), ('oreb', 'NN'), ('or', 'CC'), ('of', 'IN'), ('sinai', 'JJ'), ('didst', 'NN'), ('inspire', 'NN'), ('that', 'WDT'), ('shepherd', 'NN'), ('who', 'WP'), ('first', 'RB'), ('taught', 'VBD'), ('the', 'DT'), ('chosen', 'NN'), ('seed', 'NN'), ('in', 'IN'), ('the', 'DT'), ('beginning', 'NN'), ('how', 'WRB'), ('the', 'DT'), ('heavens', 'NNS'), ('and', 'CC'), ('earth', 'NN'), ('rose', 'VBD'), ('out', 'IN'), ('of', 'IN'), ('chaos', 'NN'), ('or', 'CC'), ('if', 'IN'), ('sion', 'NN'), ('hill', 'NN'), ('delight', 'VBD'), ('thee', 'NNS'), ('mor', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "print(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(tagger, doc):\n",
    "    return [\"/\".join(p) for p in tagger(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paradise/NN',\n",
       " 'lost/VBN',\n",
       " 'by/IN',\n",
       " 'john/NN',\n",
       " 'milton/NN',\n",
       " '1667/CD',\n",
       " 'book/NN',\n",
       " 'i/NN',\n",
       " 'of/IN',\n",
       " 'man/NN',\n",
       " 's/NN',\n",
       " 'first/JJ',\n",
       " 'disobedience/NN',\n",
       " 'and/CC',\n",
       " 'the/DT',\n",
       " 'fruit/NN',\n",
       " 'of/IN',\n",
       " 'that/DT',\n",
       " 'forbidden/JJ',\n",
       " 'tree/NN',\n",
       " 'whose/WP$',\n",
       " 'mortal/JJ',\n",
       " 'taste/NN',\n",
       " 'brought/VBD',\n",
       " 'death/NN',\n",
       " 'into/IN',\n",
       " 'the/DT',\n",
       " 'world/NN',\n",
       " 'and/CC',\n",
       " 'all/DT',\n",
       " 'our/PRP$',\n",
       " 'woe/NN',\n",
       " 'with/IN',\n",
       " 'loss/NN',\n",
       " 'of/IN',\n",
       " 'eden/JJ',\n",
       " 'till/NN',\n",
       " 'one/CD',\n",
       " 'greater/JJR',\n",
       " 'man/NN',\n",
       " 'restore/VB',\n",
       " 'us/PRP',\n",
       " 'and/CC',\n",
       " 'regain/VB',\n",
       " 'the/DT',\n",
       " 'blissful/JJ',\n",
       " 'seat/NN',\n",
       " 'sing/VBG',\n",
       " 'heavenly/RB',\n",
       " 'muse/VBP',\n",
       " 'that/IN',\n",
       " 'on/IN',\n",
       " 'the/DT',\n",
       " 'secret/JJ',\n",
       " 'top/NN',\n",
       " 'of/IN',\n",
       " 'oreb/NN',\n",
       " 'or/CC',\n",
       " 'of/IN',\n",
       " 'sinai/JJ',\n",
       " 'didst/NN',\n",
       " 'inspire/NN',\n",
       " 'that/WDT',\n",
       " 'shepherd/NN',\n",
       " 'who/WP',\n",
       " 'first/RB',\n",
       " 'taught/VBD',\n",
       " 'the/DT',\n",
       " 'chosen/NN',\n",
       " 'seed/NN',\n",
       " 'in/IN',\n",
       " 'the/DT',\n",
       " 'beginning/NN',\n",
       " 'how/WRB',\n",
       " 'the/DT',\n",
       " 'heavens/NNS',\n",
       " 'and/CC',\n",
       " 'earth/NN',\n",
       " 'rose/VBD',\n",
       " 'out/IN',\n",
       " 'of/IN',\n",
       " 'chaos/NN',\n",
       " 'or/CC',\n",
       " 'if/IN',\n",
       " 'sion/NN',\n",
       " 'hill/NN',\n",
       " 'delight/VBD',\n",
       " 'thee/NNS',\n",
       " 'mor/NN']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(pos_tag, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt as twit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = twit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('역시', 'Noun'), ('파', 'Noun'), ('이토', 'Noun'), ('치는', 'Verb'), ('재밌네요', 'Adjective'), ('ㅎㅎ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(tagger.pos(\"역시 파이토치는 재밌네요 ㅎㅎ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사과', '바나나']\n"
     ]
    }
   ],
   "source": [
    "print(tagger.nouns(\"사과는 맛있지만, 바나나는 맛없다!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('와우', 'Noun'), ('이렇게', 'Adverb'), ('신기하다', 'Adjective'), ('?', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(tagger.pos(\"와우 이렇게 신기할수가?\", stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사랑/Noun',\n",
       " '하는/Verb',\n",
       " '자/Noun',\n",
       " '여/Josa',\n",
       " '네/Noun',\n",
       " '영혼/Noun',\n",
       " '이/Josa',\n",
       " '잘/VerbPrefix',\n",
       " '됨/Verb',\n",
       " '같이/Adverb',\n",
       " '네/Noun',\n",
       " '가/Josa',\n",
       " '범사/Noun',\n",
       " '에/Josa',\n",
       " '잘/VerbPrefix',\n",
       " '되고/Verb',\n",
       " '강건/Noun',\n",
       " '하기를/Verb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tagger.pos, \"사랑하는 자여 네 영혼이 잘됨 같이 네가 범사에 잘되고 강건하기를\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
